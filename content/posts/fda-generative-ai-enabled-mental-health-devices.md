+++ 
draft = false
date = 2025-11-06T21:27:30-05:00
title = "FDA Committee meeting for generative AI-enabled mental health medical devices"
description = ""
slug = "fda-generative-ai-enabled-mental-health-devices"
authors = []
tags = []
categories = []
externalLink = ""
series = []
+++



Today the FDA held their “Digital Health Advisory Committee Meeting” to get feedback from industry experts (payers, providers, startups, etc), academics and clinicians on “Generative Artificial Intelligence-Enabled Mental Health Medical Devices.” There were a few clear themes across the sessions:

* There is a large unmet need for mental health services and therapy. This is caused by many issues: too few clinicians, lack of financial resources to seek help or access to care.
* Generative AI has a huge potential to fill the unmet need and democratise mental health care.
* AI based mental health tools should be regulated with a risk-based approach like medical devices in general.
* There should exist a taxonomy, like with self-driving cars (e.g. level 1 to level 5), for AI used in mental health care.
* Many mainstream LLMs are already being used for therapy, but have not been finetuned or rigorously tested for that use case. 
* There’s a clear need to monitor AI models once they’ve been deployed to track model drift, adverse events, suicidality, etc. Based on the questions at the event it wasn’t clear who will eventually be doing that monitoring, but my guess is that the vendor will have to take this on.
* LLM-based mental health tools or digital therapeutics show much greater engagement than traditional digital health tools of pre-2022.
* Vendors should make it clear to users that they are talking to a bot - that wasn’t always clear with existing models.

What surprised me the most was the lack of rigor when evaluating these tools. In some cases these tools weren’t evaluated and when they were evaluated it was retrospectively. Even when they were evaluated prospectively the primary endpoint was the PHQ-9. Several speakers called this out and indicated that the PHQ-9 is not the best endpoint for evaluating efficacy.

I think there’s a huge opportunity for start-ups and companies to evaluate their models with the same rigor that life science companies do with their therapies. While I understand that models have different considerations, there is still overlap and the rigor is needed for better clinical outcomes, trust and ultimately payer/regulatory buyin. 

Event Info: [https://www.fda.gov/advisory-committees/advisory-committee-calendar/november-6-2025-digital-health-advisory-committee-meeting-announcement-11062025](https://www.fda.gov/advisory-committees/advisory-committee-calendar/november-6-2025-digital-health-advisory-committee-meeting-announcement-11062025)


[Meeting Executive Summery](https://www.fda.gov/media/189391/download)
